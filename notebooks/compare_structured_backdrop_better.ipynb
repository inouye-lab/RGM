{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Function\n",
    "import time\n",
    "\n",
    "class CommunicationBackDropFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weight, bias, training, keep_ratio=0.5, comm_mask=None):\n",
    "\n",
    "        if comm_mask is None:\n",
    "            # Create a random communication mask if not provided\n",
    "            comm_mask = torch.rand(weight.size(), device=input.device) < keep_ratio  # 50% dropout\n",
    "\n",
    "        ctx.save_for_backward(input, weight, comm_mask)\n",
    "        ctx.training = training\n",
    "        output = F.linear(input, weight, bias)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Retrieve saved tensors\n",
    "        input, weight, comm_mask = ctx.saved_tensors\n",
    "\n",
    "        # Apply communication mask to weight during backward\n",
    "        masked_weight = weight * comm_mask.float()  # Convert boolean mask to float\n",
    "        grad_input = grad_output.mm(masked_weight)\n",
    "\n",
    "        # Gradients for weight and bias\n",
    "        grad_weight = grad_output.t().mm(input)\n",
    "        grad_bias = grad_output.sum(0)\n",
    "\n",
    "        return grad_input, grad_weight, grad_bias, None, None, None\n",
    "\n",
    "\n",
    "class ColumnwiseStructuredBackDropFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weight, bias, training, keep_ratio=0.5, kept_col_mask=None):\n",
    "        \"\"\"\n",
    "        input: [batch, D_in]\n",
    "        weight: [D_out, D_in]\n",
    "        \"\"\"\n",
    "        # col_mask: 1D binary vector, dtype=torch.bool or 0/1 float\n",
    "        if kept_col_mask is None:\n",
    "            # Create a random column mask if not provided\n",
    "            kept_col_mask = torch.rand(weight.size(1), device=input.device) < keep_ratio  # 50% dropout\n",
    "\n",
    "        input_reduced = input[:, kept_col_mask]  # size: [batch, D_in_reduced]\n",
    "        weight_reduced = weight[:, kept_col_mask]  # size: [D_out, D_in_reduced]\n",
    "\n",
    "        # Save only reduced input and indices\n",
    "        ctx.save_for_backward(input_reduced, weight_reduced)\n",
    "        ctx.kept_col_mask = kept_col_mask\n",
    "        ctx.input_shape = input.shape                    # full input shape\n",
    "        ctx.weight_shape = weight.shape\n",
    "\n",
    "        output = F.linear(input, weight, bias)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        grad_output: [batch, D_out]\n",
    "        weight_reduced: [D_out, D_in_reduced]\n",
    "        input_reduced: [batch, D_in_reduced]\n",
    "\n",
    "        grad_input: [batch, D_in], only for kept columns\n",
    "        grad_weight: [D_out, D_in], only kept columns\n",
    "        grad_bias: [D_out], if bias is not None\n",
    "        \"\"\"\n",
    "\n",
    "        input_reduced, weight_reduced = ctx.saved_tensors\n",
    "        kept_col_mask = ctx.kept_col_mask\n",
    "        input_shape = ctx.input_shape\n",
    "        weight_shape = ctx.weight_shape\n",
    "\n",
    "        # grad for input: [batch,D_in], only for kept columns\n",
    "        grad_input_reduced = grad_output.mm(weight_reduced)\n",
    "        grad_input = torch.zeros(input_shape, device=grad_input_reduced.device, dtype=grad_input_reduced.dtype)\n",
    "        grad_input[:, kept_col_mask] = grad_input_reduced\n",
    "\n",
    "        # grad for weight: [D_out,D_in], only kept columns\n",
    "        grad_weight_reduced = grad_output.t().mm(input_reduced)\n",
    "        grad_weight = torch.zeros(weight_shape, device=grad_weight_reduced.device, dtype=grad_weight_reduced.dtype)\n",
    "        grad_weight[:, kept_col_mask] = grad_weight_reduced\n",
    "\n",
    "        # grad for bias\n",
    "        grad_bias = grad_output.sum(0) if ctx.needs_input_grad[2] else None\n",
    "\n",
    "        return grad_input, grad_weight, grad_bias, None, None, None\n",
    "\n",
    "\n",
    "class RowwiseStructuredBackDropFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weight, bias, training, keep_ratio=0.5, kept_row_mask=None):\n",
    "        \"\"\"\n",
    "        input: [batch, D_in]\n",
    "        weight: [D_out, D_in]\n",
    "        weight_reduced: [D_out_reduced, D_in]\n",
    "        \"\"\"\n",
    "        if kept_row_mask is None:\n",
    "            # Create a random row mask if not provided\n",
    "            kept_row_mask = torch.rand(weight.size(0), device=input.device) < keep_ratio  # 50% dropout\n",
    "\n",
    "        weight_reduced = weight[kept_row_mask, :]  # size: [D_out_reduced, D_in]\n",
    "\n",
    "        # Save full input, only reduced weight, kept indices\n",
    "        ctx.save_for_backward(input, weight_reduced)\n",
    "        ctx.kept_row_mask = kept_row_mask\n",
    "        ctx.input_shape = input.shape\n",
    "        ctx.weight_shape = weight.shape\n",
    "        ctx.bias_length = bias.shape[0] if bias is not None else None\n",
    "\n",
    "        output = F.linear(input, weight, bias)\n",
    "\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        grad_output: [batch, D_out]\n",
    "        weight_reduced: [D_out_reduced, D_in]\n",
    "        input: [batch, D_in]\n",
    "\n",
    "        grad_input: [batch, D_in], only for kept rows\n",
    "        grad_weight: [D_out, D_in], only kept rows\n",
    "        grad_bias: [D_out], if bias is not None\n",
    "        \"\"\"\n",
    "        input, weight_reduced = ctx.saved_tensors\n",
    "        kept_row_mask = ctx.kept_row_mask\n",
    "        input_shape = ctx.input_shape\n",
    "        weight_shape = ctx.weight_shape\n",
    "        bias_length = ctx.bias_length\n",
    "\n",
    "        # Only propagate grad from kept outputs\n",
    "        grad_output_reduced = grad_output[:, kept_row_mask] # size: [batch, D_out_reduced]\n",
    "\n",
    "        # grad for input: [batch, D_in], only for kept rows\n",
    "        if kept_row_mask.dim() == 0:\n",
    "            # perform the outer product\n",
    "            grad_output_reduced = grad_output_reduced.unsqueeze(1)  # make it 2D\n",
    "            weight_reduced = weight_reduced.unsqueeze(0)  # make it 2D\n",
    "        grad_input = grad_output_reduced.mm(weight_reduced)  # size: [batch, D_in]\n",
    "\n",
    "        grad_weight_reduced = grad_output_reduced.t().mm(input) # size: [D_out_reduced, D_in]\n",
    "        grad_weight = torch.zeros(weight_shape, device=grad_weight_reduced.device, dtype=grad_weight_reduced.dtype)\n",
    "        grad_weight[kept_row_mask, :] = grad_weight_reduced\n",
    "\n",
    "        grad_bias = torch.zeros(bias_length, device=grad_output.device, dtype=grad_output.dtype) if bias_length else None\n",
    "        if grad_bias is not None:\n",
    "            grad_bias[kept_row_mask] = grad_output_reduced.sum(0)\n",
    "\n",
    "        return grad_input, grad_weight, grad_bias, None, None, None\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Custom layer wrappers\n",
    "class CommunicationBackDropLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, keep_ratio, bias=True):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.keep_ratio = keep_ratio\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.weight)\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / (fan_in ** 0.5)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, input, training=True):\n",
    "        return CommunicationBackDropFunction.apply(input, self.weight, self.bias, training, self.keep_ratio)\n",
    "\n",
    "\n",
    "class ColumnwiseStructuredBackDropLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, keep_ratio, bias=True):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.keep_ratio = keep_ratio\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.weight)\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / (fan_in ** 0.5)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, input, training=True):\n",
    "        return ColumnwiseStructuredBackDropFunction.apply(input, self.weight, self.bias, training, self.keep_ratio)\n",
    "\n",
    "\n",
    "class RowwiseStructuredBackDropLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, keep_ratio, bias=True):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.keep_ratio = keep_ratio\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.weight)\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / (fan_in ** 0.5)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, input, training=True):\n",
    "        return RowwiseStructuredBackDropFunction.apply(input, self.weight, self.bias, training, self.keep_ratio)"
   ],
   "id": "c2358719ab8fc16b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim=196,\n",
    "                 output_dim=10,\n",
    "                 hidden_dims=[128, 64, 32],\n",
    "                 layer_type='standard',\n",
    "                 keep_ratio=0.5,\n",
    "                 activation='relu'):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.layer_type = layer_type\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        # Build the complete architecture dimensions\n",
    "        self.layer_dims = [input_dim] + hidden_dims + [output_dim]\n",
    "\n",
    "        # Create layers based on architecture\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        for i in range(len(self.layer_dims) - 1):\n",
    "            in_dim = self.layer_dims[i]\n",
    "            out_dim = self.layer_dims[i + 1]\n",
    "\n",
    "            if layer_type == 'original':\n",
    "                layer = nn.Linear(in_dim, out_dim)\n",
    "            elif layer_type == 'communication':\n",
    "                layer = CommunicationBackDropLinear(in_dim, out_dim, keep_ratio=keep_ratio)\n",
    "            elif layer_type == 'columnwise':\n",
    "                layer = ColumnwiseStructuredBackDropLinear(in_dim, out_dim, keep_ratio=keep_ratio)\n",
    "            elif layer_type == 'rowwise':\n",
    "                layer = RowwiseStructuredBackDropLinear(in_dim, out_dim, keep_ratio=keep_ratio)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown layer_type: {layer_type}\")\n",
    "\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        # Set activation function\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "        elif activation == 'leaky_relu':\n",
    "            self.activation = nn.LeakyReLU()\n",
    "        elif activation == 'gelu':\n",
    "            self.activation = nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown activation: {activation}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten input to match input_dim\n",
    "        x = x.view(-1, self.input_dim)\n",
    "\n",
    "        # Forward through all layers except the last one with activation\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = self.activation(layer(x))\n",
    "\n",
    "        # Final layer without activation\n",
    "        x = self.layers[-1](x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def get_architecture_info(self):\n",
    "        \"\"\"Return information about the network architecture\"\"\"\n",
    "        return {\n",
    "            'layer_dims': self.layer_dims,\n",
    "            'layer_type': self.layer_type,\n",
    "            'num_layers': len(self.layers),\n",
    "            'total_params': sum(p.numel() for p in self.parameters())\n",
    "        }\n",
    "\n",
    "def get_gradients(model):\n",
    "    \"\"\"Extract gradients from model parameters\"\"\"\n",
    "    gradients = []\n",
    "    for param in model.parameters():\n",
    "        if param.grad is not None:\n",
    "            gradients.append(param.grad.clone())\n",
    "    return gradients\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"Evaluate model on test set.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "    return 100. * correct / total\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, train_loader, test_loader, num_epochs, device, model_name,\n",
    "                clear_memory_first=True, track_time=False, track_memory=False, debug=False):\n",
    "    \"\"\"Train a single model and return results dictionary with optional time, VRAM usage, and accuracy tracking.\"\"\"\n",
    "\n",
    "    # Clear GPU memory before starting if requested\n",
    "    if clear_memory_first and device.type == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Initialize time tracking variables\n",
    "    if track_time:\n",
    "        start_time = time.time()\n",
    "\n",
    "    # GPU memory tracking if available and requested\n",
    "    if track_memory and device.type == 'cuda':\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "        initial_gpu_memory = torch.cuda.memory_allocated(device) / 1024 / 1024  # MB\n",
    "        max_gpu_memory = initial_gpu_memory\n",
    "    else:\n",
    "        initial_gpu_memory = 0\n",
    "        max_gpu_memory = 0\n",
    "\n",
    "    # Lists to store epoch-wise metrics\n",
    "    epoch_losses = []\n",
    "    epoch_test_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            if debug and batch_idx >= 10:  # Limit to first 10 batches for debugging\n",
    "                break\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "            # Track GPU memory usage only if requested\n",
    "            if track_memory and device.type == 'cuda':\n",
    "                current_gpu_memory = torch.cuda.memory_allocated(device) / 1024 / 1024  # MB\n",
    "                max_gpu_memory = max(max_gpu_memory, current_gpu_memory)\n",
    "\n",
    "        # Store epoch metrics\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        epoch_losses.append(avg_loss)\n",
    "\n",
    "        # Evaluate on test set for this epoch\n",
    "        test_acc = evaluate_model(model, test_loader, device)\n",
    "        epoch_test_accuracies.append(test_acc)\n",
    "\n",
    "        # Print progress every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            train_acc = 100. * correct / total\n",
    "            print(f\" Epoch {epoch+1:2d}/{num_epochs}: Loss={avg_loss:.4f}, \"\n",
    "                  f\"Train Acc={train_acc:.2f}%, Test Acc={test_acc:.2f}%\")\n",
    "\n",
    "    # Calculate total training time only if tracking is enabled\n",
    "    if track_time:\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "\n",
    "    # Final evaluation\n",
    "    final_test_acc = epoch_test_accuracies[-1]  # Use last epoch's test accuracy\n",
    "    print(f\" ✅ {model_name} Final Test Accuracy: {final_test_acc:.2f}%\")\n",
    "\n",
    "    # Create results dictionary\n",
    "    results = {\n",
    "        'model_name': model_name,\n",
    "        'test_accuracy': final_test_acc,\n",
    "        'epoch_losses': epoch_losses,\n",
    "        'epoch_test_accuracies': epoch_test_accuracies,\n",
    "    }\n",
    "\n",
    "    # Add time tracking results if enabled\n",
    "    if track_time:\n",
    "        results.update({\n",
    "            'training_time_seconds': training_time,\n",
    "            'training_time_minutes': training_time / 60,\n",
    "        })\n",
    "\n",
    "    # Add GPU memory stats if available and tracking is enabled\n",
    "    if track_memory and device.type == 'cuda':\n",
    "        peak_gpu_memory = torch.cuda.max_memory_allocated(device) / 1024 / 1024  # MB\n",
    "        results['gpu_memory_usage'] = {\n",
    "            'initial_gpu_memory_mb': initial_gpu_memory,\n",
    "            'max_gpu_memory_mb': max_gpu_memory,\n",
    "            'peak_gpu_memory_mb': peak_gpu_memory,\n",
    "            'gpu_memory_increase_mb': peak_gpu_memory - initial_gpu_memory\n",
    "        }\n",
    "        print(f\" 🎮 GPU memory usage: {peak_gpu_memory:.2f}MB (increase: {peak_gpu_memory-initial_gpu_memory:.2f}MB)\")\n",
    "    elif track_memory and device.type != 'cuda':\n",
    "        print(f\" ⚠️ GPU not available - no VRAM tracking\")\n",
    "\n",
    "    # Print time summary only if tracking is enabled\n",
    "    if track_time:\n",
    "        print(f\" ⏱️ Training time: {training_time:.2f}s ({training_time/60:.2f}m)\")\n",
    "\n",
    "    # Optional: Clear memory after training for next model\n",
    "    if device.type == 'cuda':\n",
    "        del model, optimizer\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_training_results_time_and_space_analysis(results):\n",
    "    \"\"\"Create comprehensive visualizations of training results.\"\"\"\n",
    "    plt.style.use('seaborn-v0_8' if 'seaborn-v0_8' in plt.style.available else 'default')\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    keep_ratios = results['keep_ratios']\n",
    "    x = np.arange(len(keep_ratios))\n",
    "    width = 0.20\n",
    "\n",
    "    # Extract VRAM data from new results structure (convert MB to GB)\n",
    "    extracted_vram = {}\n",
    "    for model_name in results['model_selection']:\n",
    "        extracted_vram[model_name] = []\n",
    "        result = results['models'][model_name]\n",
    "        for kr in keep_ratios:\n",
    "            if kr in result and 'gpu_memory_usage' in results['models'][model_name][kr]:\n",
    "                vram_mb = results['models'][model_name][kr]['gpu_memory_usage']['peak_gpu_memory_mb']\n",
    "                extracted_vram[model_name].append(vram_mb / 1024)  # Convert to GB\n",
    "            else:\n",
    "                extracted_vram[model_name].append(0)  # No data available\n",
    "\n",
    "    # Extract training time data from new results structure\n",
    "    extracted_time = {}\n",
    "    for model_name in results['model_selection']:\n",
    "        extracted_time[model_name] = []\n",
    "        result = results['models'][model_name]\n",
    "        for kr in keep_ratios:\n",
    "            if kr in result and 'training_time_seconds' in results['models'][model_name][kr]:\n",
    "                time_sec = results['models'][model_name][kr]['training_time_seconds']\n",
    "                extracted_time[model_name].append(time_sec)\n",
    "            else:\n",
    "                extracted_time[model_name].append(0)  # No data available\n",
    "\n",
    "    # Plot 1: VRAM Usage Comparison\n",
    "    ax1 = axes[0]\n",
    "    for index, (model_name, vram_data) in enumerate(extracted_vram.items()):\n",
    "        ax1.bar(x+(index-1)*width, vram_data, width, label=model_name, alpha=0.8)\n",
    "\n",
    "    ax1.set_xlabel('Keep Ratio')\n",
    "    ax1.set_ylabel('Max VRAM Usage (GB)')\n",
    "    ax1.set_title('Maximum VRAM Usage Comparison')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels([f'{r:.1f}' for r in keep_ratios])\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Plot 2: Training Time Comparison\n",
    "    ax2 = axes[1]\n",
    "    for model_name, time_data in extracted_time.items():\n",
    "        ax2.plot(keep_ratios, time_data, label=model_name, linewidth=2, marker='o', markersize=6)\n",
    "    ax2.set_xlabel('Keep Ratio')\n",
    "    ax2.set_ylabel('Training Time (seconds)')\n",
    "    ax2.set_title('Training Time Comparison')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels([f'{r:.1f}' for r in keep_ratios])\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return results"
   ],
   "id": "c21eb1c0a5728568",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_and_evaluate_models(config=None):\n",
    "    \"\"\"\n",
    "    Train models with different gradient methods and compare final accuracies with plots.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Configuration dictionary with training parameters\n",
    "    \"\"\"\n",
    "    # Default configuration\n",
    "    default_config = {\n",
    "        'num_epochs': 20,  # Changed from 1 to 20 for better plotting\n",
    "        'model_selection': ['original', 'communication', 'columnwise', 'rowwise'],\n",
    "        'learning_rate': 0.001,\n",
    "        'keep_ratios': [0.3, 0.5, 0.7],\n",
    "        'batch_size_train': 1024,\n",
    "        'batch_size_test': 1024,\n",
    "        'image_size': (14, 14),\n",
    "        'dataset': 'MNIST',\n",
    "        'normalize_mean': (0.1307,),\n",
    "        'normalize_std': (0.3081,),\n",
    "        'clear_memory_between_models': True,\n",
    "        'verbose': True,\n",
    "        'optimizer': 'adam',\n",
    "        'optimizer_params': {},\n",
    "        'track_time': False,\n",
    "        'track_memory': False,\n",
    "        'debug': False  # New: debug mode to limit training batches\n",
    "    }\n",
    "\n",
    "    # Merge user config with defaults\n",
    "    if config is None:\n",
    "        config = default_config\n",
    "    else:\n",
    "        for key, value in default_config.items():\n",
    "            if key not in config:\n",
    "                config[key] = value\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    if config['verbose']:\n",
    "        print(f\"🚀 Starting Training Comparison on {device}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "    # Load data based on configuration\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(config['image_size']),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(config['normalize_mean'], config['normalize_std'])\n",
    "    ])\n",
    "\n",
    "    # Training dataset\n",
    "    if config['dataset'] == 'MNIST':\n",
    "        train_dataset = datasets.MNIST(\n",
    "            root='./data', train=True, download=True, transform=transform\n",
    "        )\n",
    "        test_dataset = datasets.MNIST(\n",
    "            root='./data', train=False, download=True, transform=transform\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Dataset {config['dataset']} not supported yet\")\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size_train'], shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config['batch_size_test'], shuffle=False)\n",
    "\n",
    "    # Results storage\n",
    "    results = {\n",
    "        'config': config,\n",
    "        'keep_ratios': config['keep_ratios'],\n",
    "        'model_selection': config['model_selection'],\n",
    "        'models': {}\n",
    "    }\n",
    "    for model_name in config['model_selection']:\n",
    "        results['models'][model_name] = {}\n",
    "\n",
    "    # Helper function to create optimizer\n",
    "    def create_optimizer(model_parameters):\n",
    "        optimizer_name = config['optimizer'].lower()\n",
    "        base_params = {'lr': config['learning_rate']}\n",
    "        base_params.update(config['optimizer_params'])\n",
    "\n",
    "        if optimizer_name == 'adam':\n",
    "            return optim.Adam(model_parameters, **base_params)\n",
    "        elif optimizer_name == 'sgd':\n",
    "            return optim.SGD(model_parameters, **base_params)\n",
    "        elif optimizer_name == 'rmsprop':\n",
    "            return optim.RMSprop(model_parameters, **base_params)\n",
    "        elif optimizer_name == 'adamw':\n",
    "            return optim.AdamW(model_parameters, **base_params)\n",
    "        else:\n",
    "            raise ValueError(f\"Optimizer '{optimizer_name}' not supported. Use 'adam', 'sgd', 'rmsprop', or 'adamw'\")\n",
    "\n",
    "    if config['verbose']:\n",
    "        print(f\"Training Configuration:\")\n",
    "        print(f\"  • Dataset: {config['dataset']} ({config['image_size'][0]}×{config['image_size'][1]})\")\n",
    "        print(f\"  • Architecture: 4-layer MLP (196→128→64→32→10)\")\n",
    "        print(f\"  • Epochs: {config['num_epochs']}\")\n",
    "        print(f\"  • Learning Rate: {config['learning_rate']}\")\n",
    "        print(f\"  • Optimizer: {config['optimizer'].upper()}\")\n",
    "        print(f\"  • Batch Size: {config['batch_size_train']} (train), {config['batch_size_test']} (test)\")\n",
    "        print(f\"  • Keep Ratios: {config['keep_ratios']}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "    # Helper function to clear memory if configured\n",
    "    def clear_memory_if_needed():\n",
    "        if config['clear_memory_between_models'] and device.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "            torch.cuda.synchronize()\n",
    "            if config['verbose']:\n",
    "                print(\"🧹 GPU memory cleared\")\n",
    "\n",
    "    # Train models with different keep ratios\n",
    "    for keep_ratio in config['keep_ratios']:\n",
    "        if config['verbose']:\n",
    "            print(f\"\\n🔧 Training Models with Keep Ratio: {keep_ratio}\")\n",
    "\n",
    "        for model_name in config['model_selection']:\n",
    "            if config['verbose']:\n",
    "                print(f\"  → Training {model_name} Model (Keep Ratio={keep_ratio:.1f})...\")\n",
    "\n",
    "            clear_memory_if_needed()\n",
    "            model = SimpleNet(layer_type=model_name, keep_ratio=keep_ratio).to(device)\n",
    "            optimizer = create_optimizer(model.parameters())\n",
    "\n",
    "            model_results = train_model(\n",
    "                model=model,\n",
    "                optimizer=optimizer,\n",
    "                train_loader=train_loader,\n",
    "                test_loader=test_loader,\n",
    "                num_epochs=config['num_epochs'],\n",
    "                device=device,\n",
    "                model_name=f\"{model_name}-{keep_ratio}\",\n",
    "                clear_memory_first=False,  # Already cleared above\n",
    "                track_time=config['track_time'],  # Disable time tracking\n",
    "                track_memory=config['track_memory']  # Disable memory tracking\n",
    "            )\n",
    "\n",
    "            # Store results with keep_ratio as key\n",
    "            if model_name not in results['models']:\n",
    "                results['models'][model_name] = {}\n",
    "            results['models'][model_name][keep_ratio] = model_results\n",
    "\n",
    "    # save results to disk with name based on config\n",
    "    results_filename = f\"training_results_{config['dataset']}_{'_'.join(config['model_selection'])}_{'_'.join(map(str, config['keep_ratios']))}_{config['optimizer']}_lr_{config['learning_rate']}.json\"\n",
    "    import json\n",
    "    with open(results_filename, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    if config['verbose']:\n",
    "        print(f\"📂 Results saved to {results_filename}\")\n",
    "    # Plot training curves\n",
    "    _plot_training_curves(results)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def _plot_training_curves(results):\n",
    "    \"\"\"Create loss and test accuracy plots for different methods.\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # Plot 1: Training Loss\n",
    "    for model_name in results['model_selection']:\n",
    "        for keep_ratio in results['keep_ratios']:\n",
    "            if keep_ratio in results['models'][model_name]:\n",
    "                loss = results['models'][model_name][keep_ratio]['epoch_losses']\n",
    "                epochs = list(range(1, len(loss) + 1))\n",
    "                ax1.plot(epochs, loss, label=f'{model_name} (keep={keep_ratio})', linewidth=2, marker='s', markersize=4)\n",
    "\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Training Loss')\n",
    "    ax1.set_title('Training Loss Over Epochs')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 2: Test Accuracy\n",
    "    for model_name in results['model_selection']:\n",
    "        for keep_ratio in results['keep_ratios']:\n",
    "            if keep_ratio in results['models'][model_name]:\n",
    "                acc = results['models'][model_name][keep_ratio]['epoch_test_accuracies']\n",
    "                epochs = list(range(1, len(acc) + 1))\n",
    "                ax2.plot(epochs, acc, label=f'{model_name} (keep={keep_ratio})', linewidth=2, marker='s', markersize=4)\n",
    "\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Test Accuracy (%)')\n",
    "    ax2.set_title('Test Accuracy Over Epochs')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print final summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"📊 FINAL RESULTS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"{'Method':<25} {'Final Test Acc':<15} {'Final Loss':<12}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for keep_ratio in results['keep_ratios']:\n",
    "        for model_name in results['model_selection']:\n",
    "            if keep_ratio in results['models'][model_name]:\n",
    "                model_results = results['models'][model_name][keep_ratio]\n",
    "                print(f\"{f'{model_name} (keep={keep_ratio})':<25} {model_results['test_accuracy']:<15.2f} {model_results['epoch_losses'][-1]:<12.4f}\")\n"
   ],
   "id": "11d7a1c72ad40263",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "config = {\n",
    "    # 'model_selection': ['original', 'communication', 'columnwise', 'rowwise'],\n",
    "    'model_selection': ['communication'],\n",
    "    'num_epochs': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'keep_ratios': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    'batch_size_train': 1024,\n",
    "    'batch_size_test': 1024,\n",
    "    'clear_memory_between_models': True,\n",
    "    'verbose': True,\n",
    "    'optimizer': 'sgd',  # New: optimizer type ('adam', 'sgd', 'rmsprop', 'adamw')\n",
    "    # 'debug': True,\n",
    "}\n",
    "\n",
    "training_results_epochs = train_and_evaluate_models(config)"
   ],
   "id": "c90e917f5c18d6bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "config = {\n",
    "    # 'model_selection': ['original', 'communication', 'columnwise', 'rowwise'],\n",
    "    'model_selection': ['communication'],\n",
    "    'num_epochs': 100,\n",
    "    'learning_rate': 1,\n",
    "    'keep_ratios': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    'batch_size_train': 1024,\n",
    "    'batch_size_test': 1024,\n",
    "    'clear_memory_between_models': True,\n",
    "    'verbose': True,\n",
    "    'optimizer': 'sgd',  # New: optimizer type ('adam', 'sgd', 'rmsprop', 'adamw')\n",
    "    'optimizer_params': {}  # New: additional optimizer parameters\n",
    "}\n",
    "\n",
    "training_results_epochs = train_and_evaluate_models(config)"
   ],
   "id": "735343316a8d760c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "config = {\n",
    "    # 'model_selection': ['original', 'communication', 'columnwise', 'rowwise'],\n",
    "    'model_selection': ['columnwise'],\n",
    "    'num_epochs': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'keep_ratios': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    'batch_size_train': 1024,\n",
    "    'batch_size_test': 1024,\n",
    "    'clear_memory_between_models': True,\n",
    "    'verbose': True,\n",
    "    'optimizer': 'sgd',  # New: optimizer type ('adam', 'sgd', 'rmsprop', 'adamw')\n",
    "    'optimizer_params': {}  # New: additional optimizer parameters\n",
    "}\n",
    "\n",
    "training_results_epochs = train_and_evaluate_models(config)"
   ],
   "id": "1c90c629dcafb64d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "config = {\n",
    "    # 'model_selection': ['original', 'communication', 'columnwise', 'rowwise'],\n",
    "    'model_selection': ['rowwise'],\n",
    "    'num_epochs': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'keep_ratios': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    'batch_size_train': 1024,\n",
    "    'batch_size_test': 1024,\n",
    "    'clear_memory_between_models': True,\n",
    "    'verbose': True,\n",
    "    'optimizer': 'sgd',  # New: optimizer type ('adam', 'sgd', 'rmsprop', 'adamw')\n",
    "    'optimizer_params': {}  # New: additional optimizer parameters\n",
    "}\n",
    "\n",
    "training_results_epochs = train_and_evaluate_models(config)"
   ],
   "id": "7d1ce429f9e5bb49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    " # load three results from disk\n",
    "import json\n",
    "import numpy as np\n",
    "def load_results_from_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "results_communication = load_results_from_file('training_results_MNIST_communication_0.1_0.3_0.5_0.7_0.9.json')\n",
    "results_columnwise = load_results_from_file('training_results_MNIST_columnwise_0.1_0.3_0.5_0.7_0.9.json')\n",
    "results_rowwise = load_results_from_file('training_results_MNIST_rowwise_0.1_0.3_0.5_0.7_0.9.json')\n",
    "restuls_original = load_results_from_file('training_results_MNIST_original_0.9.json')\n",
    "\n",
    "# plot the keep=0.1 results for all three methods\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_keep_ratio_comparison(results_communication, results_columnwise, results_rowwise, keep_ratio=0.1):\n",
    "    \"\"\"Plot comparison of different methods for a specific keep ratio.\"\"\"\n",
    "    plt.style.use('default')\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    methods = ['communication', 'columnwise', 'rowwise']\n",
    "    for method in methods:\n",
    "        results = eval(f'results_{method}')\n",
    "        # print(len(results['models'][method]['0.1']['epoch_losses']))\n",
    "        model_results = results['models'][method][f'{keep_ratio}']\n",
    "        x = list(range(1, len(model_results['epoch_test_accuracies']) + 1))\n",
    "        # make the marker different for each method\n",
    "        if method == 'communication':\n",
    "            marker = 'o'\n",
    "        elif method == 'columnwise':\n",
    "            marker = 's'\n",
    "        elif method == 'rowwise':\n",
    "            marker = 'D'\n",
    "        else:\n",
    "            marker = 'x'\n",
    "        ax.plot(x, model_results['epoch_losses'], label=f'{method}',\n",
    "                linewidth=2)\n",
    "    model_results = restuls_original['models']['original'][f'0.9']\n",
    "    x = list(range(1, len(model_results['epoch_test_accuracies']) + 1))\n",
    "    ax.plot(x, model_results['epoch_losses'], label=f'original', linewidth=2)\n",
    "    # ax.set_yscale('log')\n",
    "    ax.loglog()\n",
    "    # add a horizontal line for the original model with y = 97.7\n",
    "    # ax.axhline(y=97.7, color='pink', linestyle='--', label='Full Backprop (97.7%)', linewidth=3)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Training loss')\n",
    "    ax.set_title(f'Training loss Comparison at Keep Ratio {keep_ratio}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return results_communication, results_columnwise, results_rowwise\n",
    "# Plot comparison for keep ratio 0.1\n",
    "\n",
    "results_communication, results_columnwise, results_rowwise = plot_keep_ratio_comparison(\n",
    "    results_communication, results_columnwise, results_rowwise, keep_ratio=0.1\n",
    ")\n",
    "results_communication, results_columnwise, results_rowwise = plot_keep_ratio_comparison(\n",
    "    results_communication, results_columnwise, results_rowwise, keep_ratio=0.3\n",
    ")\n",
    "results_communication, results_columnwise, results_rowwise = plot_keep_ratio_comparison(\n",
    "    results_communication, results_columnwise, results_rowwise, keep_ratio=0.5\n",
    ")\n",
    "results_communication, results_columnwise, results_rowwise = plot_keep_ratio_comparison(\n",
    "    results_communication, results_columnwise, results_rowwise, keep_ratio=0.7\n",
    ")\n",
    "results_communication, results_columnwise, results_rowwise = plot_keep_ratio_comparison(\n",
    "    results_communication, results_columnwise, results_rowwise, keep_ratio=0.9\n",
    ")"
   ],
   "id": "b87abf6994a0cbb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "config = {\n",
    "    # 'model_selection': ['original', 'communication', 'columnwise', 'rowwise'],\n",
    "    'model_selection': ['original'],\n",
    "    'num_epochs': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'keep_ratios': [0.9],\n",
    "    'batch_size_train': 1024,\n",
    "    'batch_size_test': 1024,\n",
    "    'clear_memory_between_models': True,\n",
    "    'verbose': True,\n",
    "    'optimizer': 'sgd',  # New: optimizer type ('adam', 'sgd', 'rmsprop', 'adamw')\n",
    "    'optimizer_params': {}  # New: additional optimizer parameters\n",
    "}\n",
    "\n",
    "training_results_epochs = train_and_evaluate_models(config)\n",
    "# import json\n",
    "# load the saved tensor\n"
   ],
   "id": "cb37c6735790ef75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "config = {\n",
    "    # 'model_selection': ['original', 'communication', 'columnwise', 'rowwise'],\n",
    "    'model_selection': ['rowwise'],\n",
    "    'num_epochs': 500,\n",
    "    'learning_rate': 0.5,\n",
    "    'keep_ratios': [0.1],\n",
    "    'batch_size_train': 1024,\n",
    "    'batch_size_test': 1024,\n",
    "    'clear_memory_between_models': True,\n",
    "    'verbose': True,\n",
    "    'optimizer': 'sgd',  # New: optimizer type ('adam', 'sgd', 'rmsprop', 'adamw')\n",
    "    'optimizer_params': {}  # New: additional optimizer parameters\n",
    "}\n",
    "\n",
    "training_results_epochs = train_and_evaluate_models(config)"
   ],
   "id": "b7d585d2ed66b684",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "946fea106f778c18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "config = {\n",
    "    'model_selection': ['original', 'communication', 'columnwise', 'rowwise'],\n",
    "    'num_epochs': 1,\n",
    "    'learning_rate': 0.1,\n",
    "    'keep_ratios': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    'batch_size_train': 1024,\n",
    "    'batch_size_test': 1024,\n",
    "    'clear_memory_between_models': True,\n",
    "    'verbose': True,\n",
    "    'optimizer': 'sgd',  # New: optimizer type ('adam', 'sgd', 'rmsprop', 'adamw')\n",
    "    'track_time': True,\n",
    "    'track_memory': True,\n",
    "    'debug': True  # New: debug mode to limit training batches\n",
    "}\n",
    "\n",
    "training_results_epochs = train_and_evaluate_models(config)\n",
    "plot_training_results_time_and_space_analysis(training_results_epochs)\n",
    "print(training_results_epochs['models']['original'][0.1].keys())"
   ],
   "id": "7e7ff712afa9ac84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "config = {\n",
    "    # 'model_selection': ['original', 'communication', 'columnwise', 'rowwise'],\n",
    "    'model_selection': ['communication'],\n",
    "    'num_epochs': 100,\n",
    "    'learning_rate': 0.3,\n",
    "    'keep_ratios': [0.1],\n",
    "    'batch_size_train': 1024,\n",
    "    'batch_size_test': 1024,\n",
    "    'clear_memory_between_models': True,\n",
    "    'verbose': True,\n",
    "    'optimizer': 'sgd',  # New: optimizer type ('adam', 'sgd', 'rmsprop', 'adamw')\n",
    "    # 'debug': True,\n",
    "}\n",
    "\n",
    "training_results_epochs = train_and_evaluate_models(config)"
   ],
   "id": "b4019399b434bf1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "91aaeb91385faa47",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
